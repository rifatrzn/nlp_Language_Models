# TASK3_Language_Models ðŸ˜ŠðŸ˜Š

# Overall Goal:
In this we will work with LMs to analyze a dataset.

# Useful python packages:
For the LM, you may find the nltk package useful: https://www.nltk.org/api/nltk.lm.html 
Or you can implement the LM manually if you prefer. (Following the n-gram model.)

# Dataset
The dataset that will be used is the toxic comment dataset. This consists of toxic comments, so be cautioned when viewing the dataset. 
You can find the training and test sets here: https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge/data
The training set (train.csv) will be used for training the LM, while the test set (test.csv) and labels (test_labels.csv) will be used for testing and analyzing your models.
Take time to understand how the training set and test set are laid out.
